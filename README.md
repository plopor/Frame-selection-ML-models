# Frame-selection-ML-models
A project demonstrating various methods of Image-to-Text ML models for extracting video frames matching prompts.

Frontend in Angular, serving instructions on the submodule.
Backend in Flask, run endpoint.py

2 Approaches:

Frame extraction from videos using BLIP or GPT2 for image captioning and sentence-embedding cosine-similarity.

Frame extraction from videos using CLIP for this specific image-to-text scenario.


As my first interaction with OCR, I wanted to explore the domain and try out a few of the models and methods that were being used for this problem.
As a result, the references outline the methods that I've used as part of the research step.
